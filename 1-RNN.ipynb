{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1572817-5f56-488d-9615-049255f94e9c",
   "metadata": {},
   "source": [
    "# Learning Aug 13, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf308b79-5f2a-4c6c-84f7-df312f1ee198",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9970, 4748, 2683, 6373],\n",
       " [9970, 4748, 2683, 8011],\n",
       " [9970, 4227, 2683, 6540],\n",
       " [1639, 8660, 8960, 1878],\n",
       " [1639, 8660, 8960, 6775],\n",
       " [9384, 9970, 7881, 2683, 6468],\n",
       " [5139, 8604, 360, 8960]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the one_hot function from Keras\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "\n",
    "# List of sentences (corpus)\n",
    "sent = ['the glass of milk',\n",
    "        'the glass of juice',\n",
    "        'the cup of tea',\n",
    "        'I am a good boy',\n",
    "        'I am a good developer',\n",
    "        'understand the meaning of words',\n",
    "        'your videos are good']\n",
    "\n",
    "# Define the vocabulary size (the number of distinct \"words\" or tokens)\n",
    "voc_size = 10000  # Arbitrary large number for the size of the vocabulary\n",
    "\n",
    "# One-Hot Representation\n",
    "# The one_hot function converts each word in a sentence to a unique integer within the range of the vocabulary size\n",
    "# This representation encodes each sentence into a list of integers\n",
    "one_hot_rep = [one_hot(words, voc_size) for words in sent]\n",
    "\n",
    "# Output the one-hot representations of the sentences\n",
    "one_hot_rep  # Display the one-hot encoded representation of each sentence in the corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12c53218-01a0-47f8-843f-3ff894b82b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0, 9970, 4748, 2683, 6373],\n",
       "       [   0,    0,    0,    0, 9970, 4748, 2683, 8011],\n",
       "       [   0,    0,    0,    0, 9970, 4227, 2683, 6540],\n",
       "       [   0,    0,    0,    0, 1639, 8660, 8960, 1878],\n",
       "       [   0,    0,    0,    0, 1639, 8660, 8960, 6775],\n",
       "       [   0,    0,    0, 9384, 9970, 7881, 2683, 6468],\n",
       "       [   0,    0,    0,    0, 5139, 8604,  360, 8960]], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries and modules\n",
    "from tensorflow.keras.layers import Embedding  # For creating the Embedding layer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  # For padding sequences to a fixed length\n",
    "from tensorflow.keras.models import Sequential  # For creating a sequential model\n",
    "import numpy as np  # For numerical operations (though not directly used here)\n",
    "import pandas as pd  # For data manipulation (though not directly used here)\n",
    "\n",
    "# Define the fixed length for padding\n",
    "sent_length = 8  # The maximum length for each sentence after padding\n",
    "\n",
    "# Pad the sequences\n",
    "# The one_hot_rep list contains one-hot encoded sentences (each as a list of integers)\n",
    "# pad_sequences is used to ensure that all sentences have the same length (sent_length)\n",
    "# padding='pre': Pads at the beginning of each sequence\n",
    "# maxlen=sent_length: Ensures each sequence is padded or truncated to this length\n",
    "embedding_docs = pad_sequences(one_hot_rep, padding='pre', maxlen=sent_length)\n",
    "\n",
    "# Output the padded sequences\n",
    "embedding_docs  # Display the padded one-hot encoded sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "260b6327-2912-4112-9dd6-47653a2868a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 8, 10)             100000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100000 (390.62 KB)\n",
      "Trainable params: 100000 (390.62 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Feature representation\n",
    "dim = 10\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=voc_size, output_dim=dim, input_length=sent_lenght))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90e97a1e-b8e0-495b-b34c-ce371443db02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00870134, -0.04319935,  0.03288524, -0.04634121,  0.0322769 ,\n",
       "         0.03393401, -0.04155124, -0.00121266,  0.02294954,  0.01713358],\n",
       "       [ 0.00870134, -0.04319935,  0.03288524, -0.04634121,  0.0322769 ,\n",
       "         0.03393401, -0.04155124, -0.00121266,  0.02294954,  0.01713358],\n",
       "       [ 0.00870134, -0.04319935,  0.03288524, -0.04634121,  0.0322769 ,\n",
       "         0.03393401, -0.04155124, -0.00121266,  0.02294954,  0.01713358],\n",
       "       [ 0.00870134, -0.04319935,  0.03288524, -0.04634121,  0.0322769 ,\n",
       "         0.03393401, -0.04155124, -0.00121266,  0.02294954,  0.01713358],\n",
       "       [ 0.03360671, -0.00490683,  0.04243331, -0.03041276,  0.04366989,\n",
       "         0.01851756, -0.00270362, -0.0348999 , -0.02017366,  0.0052737 ],\n",
       "       [ 0.01419992, -0.04662051,  0.01390103,  0.04335174,  0.02910485,\n",
       "         0.0476536 ,  0.01059177, -0.04762473, -0.00821515, -0.04748931],\n",
       "       [ 0.03951428,  0.01920395,  0.02698118, -0.00295428, -0.01484007,\n",
       "         0.02776779, -0.02510238, -0.02383589, -0.01592437,  0.02315258],\n",
       "       [ 0.04354544, -0.0373993 ,  0.00013477,  0.01870929, -0.01289318,\n",
       "         0.00584574, -0.00062412,  0.0041879 ,  0.03886222, -0.00524127]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embeding_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbdfd36-8c18-4b7f-92f5-c5c0029b8d1f",
   "metadata": {},
   "source": [
    "# Review project with Simple RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4c9b7c63-b4b6-43d3-b351-ce2cb5d1726b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 500, 128)          12800000  \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12833025 (48.95 MB)\n",
      "Trainable params: 12833025 (48.95 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np  # NumPy for numerical computations\n",
    "import pandas as pd  # Pandas for data manipulation (though not used in this specific code)\n",
    "import tensorflow as tf  # TensorFlow for building and training the neural network models\n",
    "from tensorflow.keras.datasets import imdb  # IMDb dataset for sentiment analysis\n",
    "from tensorflow.keras.preprocessing import sequence  # Utility for padding sequences to a fixed length\n",
    "from tensorflow.keras.models import Sequential  # Sequential model for building the neural network\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense  # Layers for the neural network: Embedding, RNN, and Dense (fully connected)\n",
    "\n",
    "# Load the IMDb dataset\n",
    "max_features = 100000  # Maximum number of words to consider in the vocabulary (most frequent)\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)  # Load training and testing data with a limited vocabulary\n",
    "# Output the shapes of the data arrays to understand their structure\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape  # Should return the shape of the training and testing datasets\n",
    "\n",
    "# Preprocess the data by padding sequences\n",
    "max_len = 500  # Maximum length of each sequence (number of words in each review)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_len)  # Pad training sequences to ensure uniform length\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_len)  # Pad testing sequences similarly\n",
    "\n",
    "# Build a simple RNN model\n",
    "model = Sequential()  # Initialize a Sequential model, which allows stacking layers sequentially\n",
    "model.add(Embedding(input_dim=max_features, output_dim=128, input_length=max_len))  # Add an Embedding layer to convert word indices into dense vectors of fixed size (128 dimensions)\n",
    "model.add(SimpleRNN(128, activation='relu'))  # Add a SimpleRNN layer with 128 units and ReLU activation function\n",
    "model.add(Dense(1, activation=\"sigmoid\"))  # Add a Dense layer with 1 unit and sigmoid activation, suitable for binary classification (positive/negative sentiment)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Compile the model with Adam optimizer, binary cross-entropy loss, and accuracy metric\n",
    "model.summary()  # Print a summary of the model architecture\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "298767c7-006b-4525-ae50-e550f7c978e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 09:56:23.214392: W tensorflow/core/grappler/utils/graph_view.cc:849] No registered '' OpKernel for CPU devices compatible with node {{node sequential_6/simple_rnn_1/while/body/_1/sequential_6/simple_rnn_1/while/simple_rnn_cell/Relu}}\n",
      "\t.  Registered:  <no registered kernels>\n",
      "\n",
      "2024-08-13 09:56:23.252321: E tensorflow/core/grappler/optimizers/tfg_optimizer_hook.cc:134] tfg_optimizer{any(tfg-consolidate-attrs,tfg-toposort,tfg-shape-inference{graph-version=0},tfg-prepare-attrs-export)} failed: INVALID_ARGUMENT: Node sequential_6/simple_rnn_1/while/body/_1/sequential_6/simple_rnn_1/while/simple_rnn_cell/Relu has an empty op name\n",
      "\twhen importing GraphDef to MLIR module in GrapplerHook\n",
      "2024-08-13 09:56:23.274073: E tensorflow/core/grappler/optimizers/tfg_optimizer_hook.cc:134] tfg_optimizer{any(tfg-consolidate-attrs,tfg-functional-to-region,tfg.func(tfg-cf-sink),tfg-region-to-functional{force-control-capture=true},tfg-lift-legacy-call,symbol-privatize{},symbol-dce,tfg-prepare-attrs-export)} failed: INVALID_ARGUMENT: Node sequential_6/simple_rnn_1/while/body/_1/sequential_6/simple_rnn_1/while/simple_rnn_cell/Relu has an empty op name\n",
      "\twhen importing GraphDef to MLIR module in GrapplerHook\n",
      "2024-08-13 09:56:23.274639: E tensorflow/core/grappler/optimizers/tfg_optimizer_hook.cc:134] tfg_optimizer{any(tfg-consolidate-attrs,tfg-functional-to-region,tfg.func(tfg-cf-sink),tfg-region-to-functional{force-control-capture=true},tfg-lift-legacy-call,symbol-privatize{},symbol-dce,tfg-prepare-attrs-export)} failed: INVALID_ARGUMENT: Node sequential_6/simple_rnn_1/while/body/_1/sequential_6/simple_rnn_1/while/simple_rnn_cell/Relu has an empty op name\n",
      "\twhen importing GraphDef to MLIR module in GrapplerHook\n",
      "2024-08-13 09:56:23.275715: W tensorflow/core/common_runtime/optimize_function_graph_utils.cc:573] Ignoring multi-device function optimization failure: INVALID_ARGUMENT: Node 'sequential_6/simple_rnn_1/while/body/_1/sequential_6/simple_rnn_1/while/simple_rnn_cell/Relu' does not specify an operation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 70s 111ms/step - loss: 263.1048 - accuracy: 0.6340 - val_loss: 0.5771 - val_accuracy: 0.6862\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 66s 106ms/step - loss: 0.4998 - accuracy: 0.7692 - val_loss: 0.4231 - val_accuracy: 0.8172\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 64s 102ms/step - loss: 0.2955 - accuracy: 0.8745 - val_loss: 0.4072 - val_accuracy: 0.8296\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 65s 104ms/step - loss: 0.1447 - accuracy: 0.9464 - val_loss: 0.4643 - val_accuracy: 0.8508\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 64s 102ms/step - loss: 0.0670 - accuracy: 0.9775 - val_loss: 0.4435 - val_accuracy: 0.8376\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 64s 102ms/step - loss: 0.0349 - accuracy: 0.9890 - val_loss: 0.5228 - val_accuracy: 0.8122\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 63s 101ms/step - loss: 0.0733 - accuracy: 0.9741 - val_loss: 0.5615 - val_accuracy: 0.7552\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 64s 103ms/step - loss: 13.0254 - accuracy: 0.9568 - val_loss: 0.6548 - val_accuracy: 0.6472\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f38b812c8b0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import EarlyStopping callback from Keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Initialize the EarlyStopping callback\n",
    "# monitor='val_loss': The metric to be monitored during training is the validation loss\n",
    "# patience=5: Training will stop if the validation loss does not improve for 5 consecutive epochs\n",
    "# restore_best_weights=True: After stopping, the model weights will be restored to those from the epoch with the best validation loss\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model with early stopping\n",
    "# epochs=10: The model will train for a maximum of 10 epochs\n",
    "# batch_size=32: The model will update weights after every batch of 32 samples\n",
    "# validation_split=0.2: 20% of the training data will be used as validation data to monitor performance\n",
    "# callbacks=[early_stopping]: The EarlyStopping callback is passed to the model, so training can be stopped early if the validation loss does not improve\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6e250651-cfff-42ee-8526-41a7890a3c18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save model file\n",
    "model.save('simple_run_imdb.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df5e7456-66c7-4441-8b8a-a16588b782b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 82ms/step\n",
      "Review: This movie was fantastic! The acting was great and the plot was thrilling.\n",
      "Sentiment: positive\n",
      "Prediction score: 0.8728386163711548\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and modules\n",
    "from tensorflow.keras.models import load_model  # For loading the pre-trained model\n",
    "from tensorflow.keras.preprocessing import sequence  # For padding sequences to a fixed length\n",
    "\n",
    "# Load the pre-trained model\n",
    "# The model was trained previously and saved as 'simple_run_imdb.h5'\n",
    "# This model will be used for predicting the sentiment of new movie reviews\n",
    "model1 = load_model('simple_run_imdb.h5')\n",
    "\n",
    "# Function to decode the encoded review back to words\n",
    "# The IMDb dataset encodes reviews as sequences of integers corresponding to word indices\n",
    "# This function converts those integers back to the original words using a dictionary (reverse_word_index)\n",
    "def decoded_review(encoded_review):\n",
    "    # The integer indices are shifted by 3 to account for special tokens, so we subtract 3 from each index\n",
    "    # If a word index is not found in the reverse_word_index, a '?' is used as a placeholder\n",
    "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in encoded_review])\n",
    "\n",
    "# Function to preprocess text for prediction\n",
    "# Converts a raw text review into a format suitable for the model\n",
    "def preprocessing_text(text):\n",
    "    words = text.lower().split()  # Convert the review to lowercase and split it into individual words\n",
    "    encoded_review = [word_index.get(word, 2) + 3 for word in words]  # Encode the words as integers using word_index\n",
    "    padded_review = sequence.pad_sequences([encoded_review], maxlen=500)  # Pad the sequence to ensure it has a length of 500\n",
    "    return padded_review\n",
    "\n",
    "# Prediction function\n",
    "# Takes a text review, preprocesses it, and then uses the model to predict the sentiment\n",
    "def predict_sentiment(review):\n",
    "    preprocessed_input = preprocessing_text(review)  # Preprocess the input text to prepare it for the model\n",
    "    prediction = model1.predict(preprocessed_input)  # Use the model to predict sentiment\n",
    "    sentiment = 'positive' if prediction[0][0] > 0.5 else 'negative'  # Determine the sentiment based on the model's output\n",
    "    return sentiment, prediction[0][0]  # Return the sentiment and the prediction score (probability)\n",
    "\n",
    "# Example usage of the prediction function\n",
    "example_review = \"This movie was fantastic! The acting was great and the plot was thrilling.\"\n",
    "sentiment, score = predict_sentiment(example_review)  # Predict sentiment for the example review\n",
    "\n",
    "# Print the results\n",
    "print(f'Review: {example_review}')  # Output the original review text\n",
    "print(f'Sentiment: {sentiment}')  # Output the predicted sentiment (positive/negative)\n",
    "print(f'Prediction score: {score}')  # Output the model's prediction score (probability)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8aaddf9b-1691-48d2-a757-5911473c92b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-13 10:38:11.086 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-08-13 10:38:11.087 Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Import necessary libraries\n",
    "import streamlit as st\n",
    "\n",
    "# Set up the Streamlit app\n",
    "st.title('IMDB Movie Review Sentiment Analysis')\n",
    "st.write('Enter a movie review to classify it as positive or negative.')\n",
    "\n",
    "# User input\n",
    "user_input = st.text_area('Movie Review')\n",
    "\n",
    "# Check if the classify button is pressed\n",
    "if st.button('Classify'):\n",
    "    # Preprocess the user input\n",
    "    preprocessed_input = preprocessing_text(user_input)\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model1.predict(preprocessed_input)\n",
    "    sentiment = 'positive' if prediction[0][0] > 0.5 else 'negative'\n",
    "    \n",
    "    # Display the result\n",
    "    st.write(f'Sentiment: {sentiment}')\n",
    "    st.write(f'Prediction Score: {prediction[0][0]}')\n",
    "else:\n",
    "    st.write('Please enter a movie review')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a869fe-cabe-4024-a70b-6bd953757a26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
